import re
from collections import Counter

# Read and preprocess the text
with open("article.txt", "r", encoding="utf-8") as file:
    text = file.read()

# Convert to lowercase
text = text.lower()

# Remove punctuation using regex (keep only letters and spaces)
text = re.sub(r"[^a-z\s]", "", text)

# Split into words
words = text.split()

# Define stopwords

stopwords = {'the', 'a', 'an', 'and', 'or', 'in', 'on', 'at', 'of', 'for', 'to', 'is', 'it', 'this', 'that'}

# Filter out stopwords
filtered_words = [word for word in words if word not in stopwords]

# Count word frequencies
word_counts = Counter(filtered_words)

# Get top 10 most frequent words
top_words = word_counts.most_common(10)

# Print results
print("\nTop 10 Most Frequent Words:\n" + "-"*35)
for word, count in top_words:
    print(f"{word:<15} {count}")

# Simple Histogram
print("\nHistogram of Top 10 Words:")
print("-"*35)
for word, count in top_words:
    print(f"{word:<15} {'*' * count}")
